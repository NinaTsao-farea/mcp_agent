# -*- coding: utf-8 -*-
"""
Sprint 7 æ•´åˆæ¸¬è©¦ Part 1ï¼šAzure OpenAI é€£ç·šæ¸¬è©¦

æ¸¬è©¦é …ç›®ï¼š
1. Azure OpenAI é€£ç·š
2. åŸºæœ¬å°è©±åŠŸèƒ½
3. Function Callingï¼ˆæ¨¡æ“¬ï¼‰
4. Token ä½¿ç”¨è¿½è¹¤

åŸ·è¡Œæ–¹å¼ï¼š
python backend/test_sprint7_integration_openai.py
"""
import asyncio
import sys
import os
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

import structlog
from openai import AsyncAzureOpenAI
from app.services.ai_conversation_manager import AIConversationManager

logger = structlog.get_logger()

# Azure OpenAI é…ç½®ï¼ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼‰
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT", "")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY", "")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")


async def test_azure_openai_connection():
    """æ¸¬è©¦ 1: Azure OpenAI é€£ç·š"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 1: Azure OpenAI é€£ç·šæ¸¬è©¦")
    print("="*80)
    
    try:
        print(f"\n  Endpoint: {AZURE_OPENAI_ENDPOINT}")
        print(f"  Deployment: {AZURE_OPENAI_DEPLOYMENT}")
        print(f"  API Version: {AZURE_OPENAI_API_VERSION}")
        
        if not AZURE_OPENAI_API_KEY or not AZURE_OPENAI_ENDPOINT:
            print(f"\n  âœ— ç¼ºå°‘å¿…è¦çš„ç’°å¢ƒè®Šæ•¸")
            print(f"  è«‹è¨­å®š: AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT")
            return False
        
        # å‰µå»º Azure OpenAI å®¢æˆ¶ç«¯
        client = AsyncAzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
        
        print(f"\n  âœ“ Azure OpenAI å®¢æˆ¶ç«¯å‰µå»ºæˆåŠŸ")
        print(f"  Model: {AZURE_OPENAI_DEPLOYMENT}")
        
        return True
        
    except Exception as e:
        print(f"\n  âœ— Azure OpenAI é€£ç·šå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_basic_chat():
    """æ¸¬è©¦ 2: åŸºæœ¬å°è©±åŠŸèƒ½"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 2: åŸºæœ¬å°è©±åŠŸèƒ½")
    print("="*80)
    
    try:
        client = AsyncAzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
        
        # ç°¡å–®å°è©±æ¸¬è©¦
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å‹å–„çš„åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "è«‹ç”¨ä¸€å¥è©±ä»‹ç´¹å°ç£"}
        ]
        
        print(f"\n  ç™¼é€æ¸¬è©¦è¨Šæ¯...")
        response = await client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=messages,
            max_tokens=100
        )
        
        reply = response.choices[0].message.content
        print(f"\n  AI å›è¦†: {reply[:80]}...")
        print(f"  âœ“ åŸºæœ¬å°è©±åŠŸèƒ½æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"\n  âœ— åŸºæœ¬å°è©±æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_function_calling():
    """æ¸¬è©¦ 3: Function Callingï¼ˆæ¨¡æ“¬ï¼‰"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 3: Function Calling")
    print("="*80)
    
    try:
        client = AsyncAzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
        
        # å®šç¾©æ¸¬è©¦ç”¨çš„ Functions
        functions = [
            {
                "type": "function",
                "function": {
                    "name": "get_plan_details",
                    "description": "æŸ¥è©¢è³‡è²»æ–¹æ¡ˆçš„è©³ç´°è³‡è¨Š",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "plan_id": {
                                "type": "string",
                                "description": "æ–¹æ¡ˆIDï¼Œä¾‹å¦‚ï¼š999ã€1399"
                            }
                        },
                        "required": ["plan_id"]
                    }
                }
            }
        ]
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯é›»ä¿¡æ–¹æ¡ˆåŠ©æ‰‹ï¼Œå¯ä»¥æŸ¥è©¢æ–¹æ¡ˆè³‡è¨Šã€‚"},
            {"role": "user", "content": "è«‹å¹«æˆ‘æŸ¥è©¢ 999 å…ƒæ–¹æ¡ˆçš„è©³ç´°è³‡è¨Š"}
        ]
        
        print(f"\n  æ¸¬è©¦ Function Calling...")
        response = await client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=messages,
            tools=functions,
            tool_choice="auto",
            max_tokens=500
        )
        
        message = response.choices[0].message
        
        if message.tool_calls:
            for tool_call in message.tool_calls:
                print(f"\n  âœ“ AI èª¿ç”¨ Function: {tool_call.function.name}")
                print(f"  åƒæ•¸: {tool_call.function.arguments}")
            return True
        else:
            print(f"\n  âš  AI æ²’æœ‰èª¿ç”¨ Function")
            print(f"  ç›´æ¥å›ç­”: {message.content}")
            return True  # ä¸ä¸€å®šè¦èª¿ç”¨ï¼Œæ‰€ä»¥é‚„æ˜¯ç®—é€šé
            
    except Exception as e:
        print(f"\n  âœ— Function Calling æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_ai_conversation_manager():
    """æ¸¬è©¦ 4: AIConversationManager åˆå§‹åŒ–"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 4: AIConversationManager")
    print("="*80)
    
    try:
        print(f"\n  å‰µå»º AIConversationManager...")
        ai_manager = AIConversationManager()
        
        print(f"  âœ“ AIConversationManager å‰µå»ºæˆåŠŸ")
        print(f"  Model: {ai_manager.model}")
        print(f"  Max Tokens: {ai_manager.max_tokens}")
        
        # æª¢æŸ¥ Function Definitions
        functions = ai_manager._get_function_definitions()
        print(f"  âœ“ å·²è¼‰å…¥ {len(functions)} å€‹ Functions")
        
        # åˆ—å‡ºå‰5å€‹ Functions
        for i, func in enumerate(functions[:5]):
            func_name = func["function"]["name"]
            print(f"    {i+1}. {func_name}")
        
        if len(functions) > 5:
            print(f"    ... é‚„æœ‰ {len(functions) - 5} å€‹ Functions")
        
        return True
        
    except Exception as e:
        print(f"\n  âœ— AIConversationManager æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_token_calculation():
    """æ¸¬è©¦ 5: Token ä½¿ç”¨è¨ˆç®—"""
    print("\n" + "="*80)
    print("æ¸¬è©¦ 5: Token ä½¿ç”¨è¨ˆç®—")
    print("="*80)
    
    try:
        client = AsyncAzureOpenAI(
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT
        )
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯åŠ©æ‰‹"},
            {"role": "user", "content": "è«‹èªª Hello"}
        ]
        
        response = await client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=messages,
            max_tokens=50
        )
        
        usage = response.usage
        print(f"\n  Token ä½¿ç”¨:")
        print(f"    Prompt Tokens: {usage.prompt_tokens}")
        print(f"    Completion Tokens: {usage.completion_tokens}")
        print(f"    Total Tokens: {usage.total_tokens}")
        
        # è¨ˆç®—æˆæœ¬ (GPT-4o åƒ¹æ ¼)
        prompt_cost = usage.prompt_tokens / 1000 * 0.005
        completion_cost = usage.completion_tokens / 1000 * 0.015
        total_cost = prompt_cost + completion_cost
        
        print(f"\n  ä¼°è¨ˆæˆæœ¬:")
        print(f"    Prompt: ${prompt_cost:.6f}")
        print(f"    Completion: ${completion_cost:.6f}")
        print(f"    Total: ${total_cost:.6f}")
        
        print(f"\n  âœ“ Token è¨ˆç®—åŠŸèƒ½æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"\n  âœ— Token è¨ˆç®—æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("\n" + "="*80)
    print(" Sprint 7 æ•´åˆæ¸¬è©¦ Part 1: Azure OpenAI")
    print("="*80)
    print(f" åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    tests = [
        ("Azure OpenAI é€£ç·š", test_azure_openai_connection),
        ("åŸºæœ¬å°è©±åŠŸèƒ½", test_basic_chat),
        ("Function Calling", test_function_calling),
        ("AIConversationManager", test_ai_conversation_manager),
        ("Token ä½¿ç”¨è¨ˆç®—", test_token_calculation),
    ]
    
    results = []
    
    for name, test_func in tests:
        try:
            result = await test_func()
            results.append((name, result))
        except Exception as e:
            print(f"\nâœ— æ¸¬è©¦ '{name}' åŸ·è¡Œå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))
    
    # ç¸½çµ
    print("\n" + "="*80)
    print(" æ¸¬è©¦ç¸½çµ")
    print("="*80)
    
    for name, result in results:
        status = "âœ“ é€šé" if result else "âœ— å¤±æ•—"
        print(f"{status} - {name}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")
    
    if passed == total:
        print("\n" + "="*80)
        print(" ğŸ‰ Part 1 æ¸¬è©¦å®Œå…¨é€šéï¼")
        print("="*80)
        print("\nå¯ä»¥ç¹¼çºŒåŸ·è¡Œ Part 2 (MCP Servers æ¸¬è©¦)")
        return 0
    else:
        print(f"\nâœ— {total - passed} å€‹æ¸¬è©¦å¤±æ•—")
        print("è«‹ä¿®å¾©é€™äº›å•é¡Œå¾Œå†ç¹¼çºŒ")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
